# ğŸ“² SMS Spam Classification

Ce projet explore diffÃ©rentes approches de classification de texte pour dÃ©tecter les spams dans des messages SMS, Ã  lâ€™aide de plusieurs techniques de vectorisation et modÃ¨les dâ€™apprentissage automatique.

## ğŸ“ Dataset

- **SMS Spam Collection Dataset** : Chaque message est Ã©tiquetÃ© comme `ham` (non-spam) ou `spam`.
- Source : Kaggle / Google Drive
- Format : CSV (`spam.csv`)

## ğŸ› ï¸ MÃ©thodes UtilisÃ©es

### ğŸ”¹ Partie 1 : Vectorisation Classique (Bag of Words & TF-IDF)

- **Nettoyage des messages** : conversion en minuscules, suppression des caractÃ¨res spÃ©ciaux.
- **Bag of Words** et **TF-IDF** :
  - Transformation des textes avec `max_features=5000`.
- **ModÃ¨les de classification testÃ©s** :
  - Logistic Regression
  - Random Forest Classifier
  - Multi-Layer Perceptron (MLPClassifier)
- **Ã‰valuation** :
  - Validation croisÃ©e Ã  5 folds
  - Accuracy & F1-Score

### ğŸ”¹ Partie 2 : Embeddings avec Sentence Transformers

- ModÃ¨le utilisÃ© : `'all-MiniLM-L6-v2'` via `sentence-transformers`
- Chaque message est transformÃ© en vecteur sÃ©mantique (embedding)
- **ModÃ¨les testÃ©s** :
  - Logistic Regression
  - Random Forest
  - MLP
- **Ã‰valuation** :
  - Cross-validation (5 folds)

### ğŸ”¹ Partie 3 : Super Learner

- Combinaison de 3 modÃ¨les de base :
  - Logistic Regression
  - Random Forest
  - Support Vector Classifier (SVC)
- **ReprÃ©sentation utilisÃ©e** : TF-IDF
- **MÃ©tha-modÃ¨le** : RÃ©gression Logistique
- **Objectif** : Apprendre les poids optimaux de chaque base learner pour minimiser lâ€™erreur globale.

## ğŸ“Š RÃ©sultats ComparÃ©s (Exemple)

| MÃ©thode            | Accuracy | F1-Score |
|--------------------|----------|----------|
| BoW (LogReg)       | 0.982    | 0.935    |
| TF-IDF (LogReg)    | 0.984    | 0.940    |
| SBERT (LogReg)     | 0.989    | 0.961    |
| Super Learner      | 0.991    | 0.964    |

> (*Les chiffres sont Ã  ajuster selon vos rÃ©sultats exacts.*)

## ğŸ“ˆ Visualisations

- Courbes de performance en fonction de `max_features` pour BoW et TF-IDF.
- Comparaison globale des approches dans la console.

## ğŸ§  Avantages et InconvÃ©nients

| Approche      | Avantages | InconvÃ©nients |
|---------------|-----------|---------------|
| BoW/TF-IDF    | Rapide, simple | Ne capte pas le sens des mots |
| SBERT         | ReprÃ©sente la sÃ©mantique | Plus coÃ»teux en ressources |
| Super Learner | Combine les forces de chaque modÃ¨le | ImplÃ©mentation plus complexe |

## ğŸ“¦ DÃ©pendances

```bash
pip install pandas scikit-learn matplotlib sentence-transformers numpy




